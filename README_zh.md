<small>ä¸­æ–‡ | [EN](README.md) </small>
# causal-strength  ![å› æœå¼ºåº¦](https://img.shields.io/badge/causal--strength-%E2%9A%96%EF%B8%8F%20%E5%9B%A0%E6%9E%9C%E5%BC%BA%E5%BA%A6%E8%AF%84%E4%BC%B0-blue)  è¡¡é‡å› æœå…³ç³»çš„å¼ºåº¦

<a href="https://aclanthology.org/2024.findings-acl.384/">
    <img src="https://img.shields.io/badge/2024.findings-acl.384-blue.svg?style=flat-square" alt="ACL Anthology" />
</a>
<a href="https://pypi.org/project/causal-strength/">
    <img src="https://img.shields.io/pypi/v/causal-strength?style=flat-square" alt="PyPI version" />
</a>



**causal-strength** æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°é™ˆè¿°ä¹‹é—´å› æœå¼ºåº¦çš„ Python åŒ…ï¼Œä½¿ç”¨å¦‚ CESARï¼ˆå¸¦æ³¨æ„åŠ›é‡åŠ æƒçš„å› æœåµŒå…¥ç›¸ä¼¼æ€§ï¼‰ç­‰å¤šç§æŒ‡æ ‡ã€‚è¯¥åŒ…åˆ©ç”¨ [Hugging Face Transformers](https://huggingface.co/) ä¸Šçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œæä¾›é«˜æ•ˆå’Œå¯æ‰©å±•çš„è®¡ç®—ã€‚

## ç›®å½•

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->

- [ğŸ“œ å¼•ç”¨ *](#-å¼•ç”¨-)
- [ğŸŒŸ ç‰¹æ€§ *](#-ç‰¹æ€§-)
- [ğŸš€ å®‰è£… *](#-å®‰è£…-)
  - [å‰ææ¡ä»¶](#å‰ææ¡ä»¶)
  - [æ­¥éª¤](#æ­¥éª¤)
- [ğŸ› ï¸ ä½¿ç”¨  *](#-ä½¿ç”¨-)
  - [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
  - [è¯„ä¼°å› æœå¼ºåº¦](#è¯„ä¼°å› æœå¼ºåº¦)
  - [ç”Ÿæˆå› æœçƒ­åŠ›å›¾](#ç”Ÿæˆå› æœçƒ­åŠ›å›¾)
- [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

## ğŸ“œ å¼•ç”¨ ![å¼•ç”¨](https://img.shields.io/badge/å¼•ç”¨-å¿…éœ€-green) 

å¦‚æœä½ è§‰å¾—è¿™ä¸ªåŒ…æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬çš„ä»“åº“ [causal-strength](https://github.com/cui-shaobo/causal-strength) å’Œç›¸å…³ä»“åº“ [defeasibility-in-causality](https://github.com/cui-shaobo/defeasibility-in-causality) ç‚¹æ˜Ÿã€‚å¦‚æœç”¨äºå­¦æœ¯ç›®çš„ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

```bibtex
@inproceedings{cui-etal-2024-exploring,
    title = "Exploring Defeasibility in Causal Reasoning",
    author = "Cui, Shaobo  and
      Milikic, Lazar  and
      Feng, Yiyang  and
      Ismayilzada, Mete  and
      Paul, Debjit  and
      Bosselut, Antoine  and
      Faltings, Boi",
    booktitle = "Findings of the Association for Computational Linguistics ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.384",
    doi = "10.18653/v1/2024.findings-acl.384",
    pages = "6433--6452",
}
```

## ğŸ› ï¸ ä½¿ç”¨æ–¹æ³•  ![Usage](https://img.shields.io/badge/Usage-Instructions-green)

### è¯„ä¼°å› æœå¼ºåº¦

`evaluate` å‡½æ•°ç”¨äºè®¡ç®—ä¸¤ä¸ªé™ˆè¿°ä¹‹é—´çš„å› æœå¼ºåº¦ã€‚

1. ä½¿ç”¨ CESAR æ¨¡å‹:

    ```python
    from causalstrength import evaluate
    
    # Test CESAR Model
    s1_cesar = "Tom is very hungry now."
    s2_cesar = "He goes to McDonald for some food."
    
    print("Testing CESAR model:")
    cesar_score = evaluate(s1_cesar, s2_cesar, model_name='CESAR', model_path='shaobocui/cesar-bert-large')
    print(f"CESAR Causal strength between \"{s1_cesar}\" and \"{s2_cesar}\": {cesar_score:.4f}")
    ```
    è¾“å‡ºå¦‚ä¸‹: 
    ```plaintext
    Testing CESAR model:
    CESAR Causal strength between "Tom is very hungry now." and "He goes to McDonald for some food.": 0.4482
    ```
   
2. ä½¿ç”¨ CEQ æ¨¡å‹:

   ```python
    from causalstrength import evaluate

    # Test CEQ Model
    s1_ceq = "Tom is very hungry now."
    s2_ceq = "He goes to McDonald for some food."
    
    print("\nTesting CEQ model:")
    ceq_score = evaluate(s1_ceq, s2_ceq, model_name='CEQ')
    print(f"CEQ Causal strength between \"{s1_ceq}\" and \"{s2_ceq}\": {ceq_score:.4f}")
    ```
    è¾“å‡ºå¦‚ä¸‹: 
    ```plaintext
    Testing CEQ model:
    CEQ Causal strength between "Tom is very hungry now." and "He goes to McDonald for some food.": 0.0168
    ```

**å‚æ•°è¯´æ˜ï¼š**

- `s1` (str): åŸå› é™ˆè¿°ã€‚
- `s2` (str): ç»“æœé™ˆè¿°ã€‚
- `model_name` (str): ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆå¦‚ `'CESAR'`, `'CEQ'` ç­‰ï¼‰ã€‚
- `model_path` (str): Hugging Face æ¨¡å‹æ ‡è¯†ç¬¦æˆ–æ¨¡å‹çš„æœ¬åœ°è·¯å¾„ã€‚

### ç”Ÿæˆå› æœçƒ­åŠ›å›¾

ä½¿ç”¨çƒ­åŠ›å›¾å¯è§†åŒ– word-level çš„ å› æœå¼ºåº¦: 

```python
from causalstrength.visualization.causal_heatmap import plot_causal_heatmap

# Statements to visualize
s1 = "Tom is very hungry now."
s2 = "He goes to McDonald for some food."

# Generate heatmap
plot_causal_heatmap(
    s1,
    s2,
    model_name='shaobocui/cesar-bert-large',
    save_path='causal_heatmap.pdf'
)
```

è¾“å‡ºå¦‚ä¸‹: 
```plaintext
Testing CESAR model:
Warning: The sliced score_map dimensions do not match the number of tokens.
The causal heatmap is saved to ./figures/causal_heatmap.png
```

The causal heatmap is as follows: 
![Example Image](https://github.com/cui-shaobo/public-images/raw/main/causal-strength/heatmap.png)

## ğŸ“š å‚è€ƒæ–‡çŒ® ![References](https://img.shields.io/badge/References-Scholarly-green)
1. Cui, Shaobo, et al. "Exploring Defeasibility in Causal Reasoning." Findings of the Association for Computational Linguistics ACL 2024. 2024. 
2. Du, Li, et al. "e-CARE: a New Dataset for Exploring Explainable Causal Reasoning." Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2022.